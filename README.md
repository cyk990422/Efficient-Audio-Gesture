# Efficient-Audio-Gesture

This is the official repository of the two papers.

**ðŸ”¥(AAAI 2025) DIDiffGes: Decoupled Semi-Implicit Diffusion Models for Real-time Gesture Generation from Speech**
> *The 39th Annual AAAI Conference on Artificial Intelligence (AAAI), 2025*

**ðŸ”¥(3DV 2025) HoleGest: Decoupled Diffusion and Motion Priors for Generating Holisticly Expressive Co-speech Gestures**
> *International Conference on 3D Vision 2025 (3DV), 2025*

**[[Project Page](https://hologest.github.io/)]**

# Method
![Image](https://github.com/user-attachments/assets/4472d621-1fb1-4c6b-a155-2ccfa5a8532c)

We used an avatar to conduct an audio narration of our method, vividly elaborating on the details of our method to everyone.



# News :triangular_flag_on_post:
- [2024/12/15] **DIDiffGes got accepted by AAAI 2025!** ðŸŽ‰
- [2024/11/10] **HoloGest got accepted by 3DV 2025!** ðŸŽ‰


## 1. Getting started

This code was tested on `NVIDIA GeForce RTX 3070 Ti` and requires:

* conda3 or miniconda3

```
conda create -n EAG python=3.7
conda activate EAG
pip install -r requirements.txt 
```

## 2. Quick Start

